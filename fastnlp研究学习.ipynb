{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 2 datasets:\n",
      "\tdev has 3219 instances.\n",
      "\ttrain has 10142 instances.\n",
      "In total 1 vocabs:\n",
      "\tchars has 5844 entries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import BertEmbedding\n",
    "from fastNLP.models import BertForQuestionAnswering\n",
    "from fastNLP.core.losses import CMRC2018Loss\n",
    "from fastNLP.core.metrics import CMRC2018Metric\n",
    "from fastNLP.io.pipe.qa import CMRC2018BertPipe\n",
    "from fastNLP import Trainer, BucketSampler\n",
    "from fastNLP import WarmupCallback, GradientClipCallback\n",
    "from fastNLP.core.optimizer import AdamW\n",
    "\n",
    "\n",
    "data_bundle = CMRC2018BertPipe().process_from_file()\n",
    "\n",
    "print(data_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+------------+--------------+---------------+--------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
       "| title      | context      | question      | answers      | answer_starts | id        | context_len | raw_chars     | target_start | target_end | chars     |\n",
       "+------------+--------------+---------------+--------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
       "| 范廷颂...  | 范廷颂枢...  | 范廷颂是什... | ['1963年...  | [30]          | TRAIN_... | 492         | ['范', '廷... | 30           | 34         | [665, ... |\n",
       "| 范廷颂...  | 范廷颂枢...  | 1990年，范... | ['1990年...  | [41]          | TRAIN_... | 491         | ['范', '廷... | 41           | 61         | [665, ... |\n",
       "| 范廷颂...  | 范廷颂枢...  | 范廷颂是于... | ['范廷颂...  | [97]          | TRAIN_... | 494         | ['范', '廷... | 97           | 125        | [665, ... |\n",
       "| 范廷颂...  | 范廷颂枢...  | 1994年3月...  | ['1994年...  | [548]         | TRAIN_... | 489         | ['5', '日'... | 439          | 488        | [31, 3... |\n",
       "| 范廷颂...  | 范廷颂枢...  | 范廷颂是何... | ['范廷颂...  | [759]         | TRAIN_... | 497         | ['主', '教... | 476          | 496        | [61, 1... |\n",
       "| 安雅·罗... | 安雅·罗素... | 安雅·罗素...  | ['《全美...  | [26]          | TRAIN_... | 488         | ['安', '雅... | 26           | 41         | [243, ... |\n",
       "| 安雅·罗... | 安雅·罗素... | Russell T...  | ['有前途...  | [247]         | TRAIN_... | 479         | ['安', '雅... | 247          | 253        | [243, ... |\n",
       "| 安雅·罗... | 安雅·罗素... | 安雅·罗素...  | ['《Jet》... | [706]         | TRAIN_... | 489         | ['a', 'n',... | 469          | 488        | [25, 4... |\n",
       "| 安雅·罗... | 安雅·罗素... | 毕业后的安... | ['售货员...  | [202]         | TRAIN_... | 491         | ['安', '雅... | 202          | 204        | [243, ... |\n",
       "| 岬太郎...  | 为日本漫...  | 岬太郎在第... | ['大空翼...  | [84]          | TRAIN_... | 488         | ['为', '日... | 84           | 86         | [9, 39... |\n",
       "| 岬太郎...  | 为日本漫...  | 日本队夺得... | ['在决赛...  | [156]         | TRAIN_... | 486         | ['为', '日... | 156          | 195        | [9, 39... |\n",
       "| 岬太郎...  | 为日本漫...  | 岬太郎与谁... | ['他与松...  | [391]         | TRAIN_... | 490         | ['为', '日... | 391          | 460        | [9, 39... |\n",
       "| NGC 62...  | NGC 6231...  | NGC 6231的... | ['赤经16...  | [27]          | TRAIN_... | 370         | ['N', 'G',... | 27           | 44         | [421, ... |\n",
       "| NGC 62...  | NGC 6231...  | NGC 6231的... | ['约为三...  | [88]          | TRAIN_... | 370         | ['N', 'G',... | 88           | 95         | [421, ... |\n",
       "| NGC 62...  | NGC 6231...  | NGC 6231星... | ['星团内...  | [108]         | TRAIN_... | 370         | ['N', 'G',... | 108          | 125        | [421, ... |\n",
       "| NGC 62...  | NGC 6231...  | NGC 6231被... | ['Lumino...  | [213]         | TRAIN_... | 370         | ['N', 'G',... | 213          | 221        | [421, ... |\n",
       "| NGC 62...  | NGC 6231...  | NGC 6231分... | ['这个天...  | [267]         | TRAIN_... | 370         | ['N', 'G',... | 267          | 369        | [421, ... |\n",
       "| 国际初...  | 国际初中...  | 国际初中科... | ['15岁或...  | [61]          | TRAIN_... | 489         | ['国', '际... | 61           | 69         | [20, 4... |\n",
       "| 国际初...  | 国际初中...  | 次比赛最早... | ['2004年...  | [86]          | TRAIN_... | 493         | ['国', '际... | 86           | 90         | [20, 4... |\n",
       "| 国际初...  | 国际初中...  | 试验系考试... | ['物理、...  | [185]         | TRAIN_... | 496         | ['国', '际... | 185          | 193        | [20, 4... |\n",
       "| 国际初...  | 国际初中...  | 实验系考试... | ['实验系...  | [397]         | TRAIN_... | 493         | ['国', '际... | 397          | 435        | [20, 4... |\n",
       "| 国际初...  | 国际初中...  | 从第一届到... | ['从第一...  | [463]         | TRAIN_... | 482         | ['a', 't',... | 446          | 481        | [25, 6... |\n",
       "| 江苏路...  | 江苏路街...  | 江苏路街道... | ['长宁区...  | [11]          | TRAIN_... | 434         | ['江', '苏... | 11           | 13         | [353, ... |\n",
       "| 江苏路...  | 江苏路街...  | 江苏路街道... | ['下辖13...  | [126]         | TRAIN_... | 434         | ['江', '苏... | 126          | 134        | [353, ... |\n",
       "| 江苏路...  | 江苏路街...  | 江苏路街道... | ['较著名...  | [237]         | TRAIN_... | 434         | ['江', '苏... | 237          | 287        | [353, ... |\n",
       "| 黄独       | 黄独（学...  | 黄独分布在... | ['分布于...  | [150]         | TRAIN_... | 424         | ['黄', '独... | 150          | 227        | [375, ... |\n",
       "| 黄独       | 黄独（学...  | 黄独生长的... | ['生长于...  | [229]         | TRAIN_... | 424         | ['黄', '独... | 229          | 247        | [375, ... |\n",
       "| 黄独       | 黄独（学...  | 黄独的英文... | ['英文别...  | [320]         | TRAIN_... | 424         | ['黄', '独... | 320          | 335        | [375, ... |\n",
       "| 黄独       | 黄独（学...  | 什么是黄独... | ['黄独（...  | [0]           | TRAIN_... | 424         | ['黄', '独... | 0            | 17         | [375, ... |\n",
       "| 黄独       | 黄独（学...  | 黄独的外皮... | ['外皮黄...  | [57]          | TRAIN_... | 424         | ['黄', '独... | 57           | 61         | [375, ... |\n",
       "| 烯酮       | 烯酮是含...  | 什么是烯酮... | ['烯酮是...  | [0]           | TRAIN_... | 322         | ['烯', '酮... | 0            | 22         | [1903,... |\n",
       "| ...        | ...          | ...           | ...          | ...           | ...       | ...         | ...           | ...          | ...        | ...       |\n",
       "+------------+--------------+---------------+--------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
       "| title     | context     | question      | answers     | answer_starts | id        | context_len | raw_chars     | target_start | target_end | chars     |\n",
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
       "| 范廷颂... | 范廷颂枢... | 范廷颂是什... | ['1963年... | [30]          | TRAIN_... | 492         | ['范', '廷... | 30           | 34         | [665, ... |\n",
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('train')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'范廷颂'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('train')[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'范廷颂是什么时候被任为主教的？'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('train')[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1963年']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('train')[0]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('train')[0]['answer_starts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastNLP.io.pipe.qa.CMRC2018BertPipe"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMRC2018BertPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function fastNLP.io.pipe.qa.CMRC2018BertPipe.process_from_file>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMRC2018BertPipe.process_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "本文件中的Pipe主要用于处理问答任务的数据。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from .pipe import Pipe\n",
    "\n",
    "from .. import DataBundle\n",
    "\n",
    "from ..loader.qa import CMRC2018Loader\n",
    "\n",
    "from .utils import get_tokenizer\n",
    "\n",
    "from ...core import DataSet\n",
    "\n",
    "from ...core import Vocabulary\n",
    "\n",
    "\n",
    "__all__ = ['CMRC2018BertPipe']\n",
    "\n",
    "\n",
    "def _concat_clip(data_bundle, max_len, concat_field_name='raw_chars'):\n",
    "    r\"\"\"\n",
    "    处理data_bundle中的DataSet，将context与question按照character进行tokenize，然后使用[SEP]将两者连接起来。\n",
    "\n",
    "    会新增field: context_len(int), raw_words(list[str]), target_start(int), target_end(int)其中target_start\n",
    "    与target_end是与raw_chars等长的。其中target_start和target_end是前闭后闭的区间。\n",
    "\n",
    "    :param DataBundle data_bundle: 类似[\"a\", \"b\", \"[SEP]\", \"c\", ]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tokenizer = get_tokenizer('cn-char', lang='cn')\n",
    "    for name in list(data_bundle.datasets.keys()):\n",
    "        ds = data_bundle.get_dataset(name)\n",
    "        data_bundle.delete_dataset(name)\n",
    "        new_ds = DataSet()\n",
    "        for ins in ds:\n",
    "            new_ins = deepcopy(ins)\n",
    "            context = ins['context']\n",
    "            question = ins['question']\n",
    "\n",
    "            cnt_lst = tokenizer(context)\n",
    "            q_lst = tokenizer(question)\n",
    "\n",
    "            answer_start = -1\n",
    "\n",
    "            if len(cnt_lst) + len(q_lst) + 3 > max_len:  \n",
    "                # 预留开头的[CLS]和[SEP]和中间的[sep]\n",
    "                if 'answer_starts' in ins and 'answers' in ins:\n",
    "                    answer_start = int(ins['answer_starts'][0])\n",
    "                    answer = ins['answers'][0]\n",
    "                    answer_end = answer_start + len(answer)\n",
    "                    if answer_end > max_len - 3 - len(q_lst):\n",
    "                        span_start = answer_end + 3 + len(q_lst) - max_len\n",
    "                        span_end = answer_end\n",
    "                    else:\n",
    "                        span_start = 0\n",
    "                        span_end = max_len - 3 - len(q_lst)\n",
    "                    cnt_lst = cnt_lst[span_start:span_end]\n",
    "                    answer_start = int(ins['answer_starts'][0])\n",
    "                    answer_start -= span_start\n",
    "                    answer_end = answer_start + len(ins['answers'][0])\n",
    "                else:\n",
    "                    cnt_lst = cnt_lst[:max_len - len(q_lst) - 3]\n",
    "            else:\n",
    "                if 'answer_starts' in ins and 'answers' in ins:\n",
    "                    answer_start = int(ins['answer_starts'][0])\n",
    "                    answer_end = answer_start + len(ins['answers'][0])\n",
    "\n",
    "            tokens = cnt_lst + ['[SEP]'] + q_lst\n",
    "            new_ins['context_len'] = len(cnt_lst)\n",
    "            new_ins[concat_field_name] = tokens\n",
    "\n",
    "            if answer_start != -1:\n",
    "                new_ins['target_start'] = answer_start\n",
    "                new_ins['target_end'] = answer_end - 1\n",
    "\n",
    "            new_ds.append(new_ins)\n",
    "        data_bundle.set_dataset(new_ds, name)\n",
    "\n",
    "    return data_bundle\n",
    "\n",
    "\n",
    "class CMRC2018BertPipe(Pipe):\n",
    "    r\"\"\"\n",
    "    处理之后的DataSet将新增以下的field(传入的field仍然保留)\n",
    "\n",
    "    .. csv-table::\n",
    "        :header: \"context_len\", \"raw_chars\",\n",
    "        \"target_start\", \"target_end\", \"chars\"\n",
    "        \n",
    "        492, ['范', '廷', '颂... ], 30, 34, \"[21, 25, ...]\"\n",
    "        491, ['范', '廷', '颂... ], 41, 61, \"[21, 25, ...]\"\n",
    "\n",
    "        \".\", \"...\", \"...\",\"...\", \"...\"\n",
    "\n",
    " #将结果拼接一下的结果\n",
    "    raw_words列是context与question拼起来的结果(连接的地方加入了[SEP])\n",
    "    ，words是转为index的值, target_start为答案start的index\n",
    "    ，target_end为答案end的index\n",
    "    （闭区间）；context_len指示的是words列中context的长度。\n",
    "\n",
    "    其中各列的meta信息如下:\n",
    "    \n",
    "    .. code::\n",
    "    \n",
    "        +-------------+-------------+-----------+--------------+------------+-------+---------+\n",
    "        | field_names | context_len | raw_chars | target_start | target_end | chars | answers |\n",
    "        +-------------+-------------+-----------+--------------+------------+-------+---------|\n",
    "        |   is_input  |    False    |   False   |    False     |   False    |  True |  False  |\n",
    "        |  is_target  |     True    |    True   |     True     |    True    | False |  True   |\n",
    "        | ignore_type |    False    |    True   |    False     |   False    | False |  True   |\n",
    "        |  pad_value  |      0      |     0     |      0       |     0      |   0   |   0     |\n",
    "        +-------------+-------------+-----------+--------------+------------+-------+---------+\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, max_len=510):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def process(self, data_bundle: DataBundle) -> DataBundle:\n",
    "        r\"\"\"\n",
    "        传入的DataSet应该具备以下的field\n",
    "\n",
    "        .. csv-table::\n",
    "           :header:\"title\", \"context\", \"question\", \"answers\", \"answer_starts\", \"id\"\n",
    "\n",
    "           \"范廷颂\", \"范廷颂枢机（，），圣名保禄·若瑟（）...\", \"范廷颂是什么时候被任为主教的？\", [\"1963年\"], [\"30\"], \"TRAIN_186_QUERY_0\"\n",
    "           \"范廷颂\", \"范廷颂枢机（，），圣名保禄·若瑟（）...\", \"1990年，范廷颂担任什么职务？\", [\"1990年被擢升为天...\"], [\"41\"],\"TRAIN_186_QUERY_1\"\n",
    "           \"...\", \"...\", \"...\",\"...\", \".\", \"...\"\n",
    "\n",
    "        :param data_bundle:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data_bundle = _concat_clip(data_bundle\n",
    "                                   , max_len=self.max_len\n",
    "                                   , concat_field_name='raw_chars')\n",
    "\n",
    "        src_vocab = Vocabulary()\n",
    "        src_vocab.from_dataset(*[ds for name, ds in data_bundle.iter_datasets() \n",
    "                                 if 'train' in name],\n",
    "                               field_name='raw_chars',\n",
    "                               no_create_entry_dataset=[ds for name, ds in data_bundle.iter_datasets()\n",
    "                                                        if 'train' not in name]\n",
    "                               )\n",
    "        src_vocab.index_dataset(*data_bundle.datasets.values()\n",
    "                                , field_name='raw_chars', new_field_name='chars')\n",
    "        data_bundle.set_vocab(src_vocab, 'chars')\n",
    "\n",
    "        data_bundle.set_ignore_type('raw_chars', 'answers', flag=True)\n",
    "        data_bundle.set_input('chars')\n",
    "        data_bundle.set_target('raw_chars', \n",
    "                               'answers',\n",
    "                               'target_start',\n",
    "                               'target_end',\n",
    "                               'context_len')\n",
    "\n",
    "        return data_bundle\n",
    "\n",
    "    #process最重要\n",
    "    def process_from_file(self, paths=None) -> DataBundle:\n",
    "        data_bundle = CMRC2018Loader().load(paths)\n",
    "        return self.process(data_bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMRC2018Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "该文件中的Loader主要用于读取问答式任务的数据\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from . import Loader\n",
    "import json\n",
    "from ...core import DataSet, Instance\n",
    "\n",
    "__all__ = ['CMRC2018Loader']\n",
    "\n",
    "\n",
    "class CMRC2018Loader(Loader):\n",
    "    r\"\"\"\n",
    "    请直接使用从fastNLP下载的数据进行处理。\n",
    "    该数据集未提供测试集，测试需要通过上传到对应的系统进行评测\n",
    "\n",
    "    读取之后训练集DataSet将具备以下的内容，每个问题的答案只有一个\n",
    "\n",
    "    .. csv-table::\n",
    "       :header:\"title\", \"context\", \"question\", \"answers\", \"answer_starts\", \"id\"\n",
    "\n",
    "       \"范廷颂\", \"范廷颂枢机（，），圣名保禄·若瑟（）...\", \"范廷颂是什么时候被任为主教的？\", [\"1963年\"], [\"30\"], \"TRAIN_186_QUERY_0\"\n",
    "       \"范廷颂\", \"范廷颂枢机（，），圣名保禄·若瑟（）...\", \"1990年，范廷颂担任什么职务？\", [\"1990年被擢升为天...\"], [\"41\"],\"TRAIN_186_QUERY_1\"\n",
    "       \"...\", \"...\", \"...\",\"...\", \".\", \"...\"\n",
    "\n",
    "    其中title是文本的标题，多条记录可能是相同的title\n",
    "    ；id是该问题的id，具备唯一性\n",
    "\n",
    "    验证集DataSet将具备以下的内容\n",
    "    ，每个问题的答案可能有三个(有时候只是3个重复的答案)\n",
    "\n",
    "    .. csv-table::\n",
    "       :header: \"title\", \"context\", \"question\", \"answers\", \"answer_starts\", \"id\"\n",
    "\n",
    "       \"战国无双3\", \"《战国无双3》（）是由光荣和ω-force开发...\", \"《战国无双3》是由哪两个公司合作开发的？\", \"['光荣和ω-force', '光荣和ω-force', '光荣和ω-force']\", \"[30, 30, 30]\", \"DEV_0_QUERY_0\"\n",
    "       \"战国无双3\", \"《战国无双3》（）是由光荣和ω-force开发...\", \"男女主角亦有专属声优这一模式是由谁改编的？\", \"['村雨城', '村雨城', '任天堂游戏谜之村雨城']\", \"[226, 226, 219]\", \"DEV_0_QUERY_1\"\n",
    "       \"...\", \"...\", \"...\",\"...\", \".\", \"...\"\n",
    "\n",
    "    其中answer_starts是从0开始的index。\n",
    "    例如\"我来自a复旦大学？\"，其中\"复\"的开始index为4。\n",
    "    另外\"Russell评价说\"中的说的index为9, 因为\n",
    "    英文和数字都直接按照character计量的。\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _load(self, path: str) -> DataSet:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)['data']\n",
    "            ds = DataSet()\n",
    "            for entry in data:\n",
    "                title = entry['title']\n",
    "                para = entry['paragraphs'][0]\n",
    "                context = para['context']\n",
    "                qas = para['qas']\n",
    "                for qa in qas:\n",
    "                    question = qa['question']\n",
    "                    ans = qa['answers']\n",
    "                    answers = []\n",
    "                    answer_starts = []\n",
    "                    id = qa['id']\n",
    "                    for an in ans:\n",
    "                        answers.append(an['text'])\n",
    "                        answer_starts.append(an['answer_start'])\n",
    "                    ds.append(Instance(title=title, context=context, question=question, answers=answers,\n",
    "                                       answer_starts=answer_starts,id=id))\n",
    "        return ds\n",
    "\n",
    "    def download(self) -> str:\n",
    "        r\"\"\"\n",
    "        如果您使用了本数据，请引用A Span-Extraction Dataset for Chinese Machine Reading Comprehension. Yiming Cui, Ting Liu, etc.\n",
    "\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        output_dir = self._get_dataset_path('cmrc2018')\n",
    "        return output_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fastNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastNLP import DataSet,Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=r'C:\\Users\\Administrator\\.fastNLP\\dataset\\cmrc2018\\dev.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)['data']\n",
    "            ds = DataSet()\n",
    "            for entry in data:\n",
    "                title = entry['title']\n",
    "#                 print(type(title))\n",
    "#                 print(type(title))\n",
    "                para = entry['paragraphs'][0]\n",
    "#                 print(type(para))\n",
    "                context = para['context']\n",
    "#                 print(type(context))\n",
    "                qas = para['qas']\n",
    "#                 print(type(qas))\n",
    "                for qa in qas:\n",
    "                    question = qa['question']\n",
    "                    ans = qa['answers']\n",
    "                    answers = []\n",
    "                    answer_starts = []\n",
    "                    id = qa['id']\n",
    "                    for an in ans:\n",
    "                        answers.append(an['text'])\n",
    "                        answer_starts.append(an['answer_start'])\n",
    "                    ds.append(Instance(title=title, context=context, question=question, answers=answers,\n",
    "                                       answer_starts=answer_starts,id=id))\n",
    "#                     print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+----------------+-----------------+----------------+-------------------+----------------+\n",
       "| title     | context        | question        | answers        | answer_starts     | id             |\n",
       "+-----------+----------------+-----------------+----------------+-------------------+----------------+\n",
       "| 战国无双3 | 《战国无双3... | 男女主角亦有... | ['村雨城', ... | [226, 226, 219... | DEV_0_QUERY... |\n",
       "+-----------+----------------+-----------------+----------------+-------------------+----------------+"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 这个算法估计是做机器阅读倒是很不错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'战国无双3'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'《战国无双3》（）是由光荣和ω-force开发的战国无双系列的正统第三续作。本作以三大故事为主轴，分别是以武田信玄等人为主的《关东三国志》，织田信长等人为主的《战国三杰》，石田三成等人为主的《关原的年轻武者》，丰富游戏内的剧情。此部份专门介绍角色，欲知武器情报、奥义字或擅长攻击类型等，请至战国无双系列1.由于乡里大辅先生因故去世，不得不寻找其他声优接手。从猛将传 and Z开始。2.战国无双 编年史的原创男女主角亦有专属声优。此模式是任天堂游戏谜之村雨城改编的新增模式。本作中共有20张战场地图（不含村雨城），后来发行的猛将传再新增3张战场地图。但游戏内战役数量繁多，部分地图会有兼用的状况，战役虚实则是以光荣发行的2本「战国无双3 人物真书」内容为主，以下是相关介绍。（注：前方加☆者为猛将传新增关卡及地图。）合并本篇和猛将传的内容，村雨城模式剔除，战国史模式可直接游玩。主打两大模式「战史演武」&「争霸演武」。系列作品外传作品'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'男女主角亦有专属声优这一模式是由谁改编的？'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['村雨城', '村雨城', '任天堂游戏谜之村雨城']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[226, 226, 219]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]['answer_starts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[1]['answer_starts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEV_0_QUERY_1'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'fastNLP.core.dataset.DataSet'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_bundle=ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastNLP.io import CMRC2018Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastNLP.io.loader.qa.CMRC2018Loader"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMRC2018Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenize_method='cn-char'\n",
    "# tokenize_method='spacy'\n",
    "lang='cn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _raw_split(sent):\n",
    "    return sent.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _cn_char_split(sent):\n",
    "    return [chars for chars in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "\n",
    ":param str tokenize_method: 获取tokenzier方法\n",
    ":param str lang: 语言，当前仅支持en\n",
    ":return: 返回tokenize函数\n",
    "\"\"\"\n",
    "tokenizer_dict = {\n",
    "    'spacy': None,\n",
    "    'raw': _raw_split,\n",
    "    'cn-char': _cn_char_split,\n",
    "}\n",
    "if tokenize_method == 'spacy':\n",
    "    import spacy\n",
    "    spacy.prefer_gpu()\n",
    "    if lang != 'en':\n",
    "        raise RuntimeError(\"Spacy only supports en right right.\")\n",
    "    # 估计目前是不支持spacy用法，所以才有这么回事\n",
    "    #到时候想法子改一下参数就行了\n",
    "    en = spacy.load(lang)\n",
    "    tokenizer = lambda x: [w.text for w in en.tokenizer(x)]\n",
    "elif tokenize_method in tokenizer_dict:\n",
    "    tokenizer = tokenizer_dict[tokenize_method]\n",
    "else:\n",
    "    raise RuntimeError(f\"Only support {tokenizer_dict.keys()} tokenizer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len=510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastNLP.io import DataBundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《战国无双3》（）是由光荣和ω-force开发的战国无双系列的正统第三续作。本作以三大故事为主轴，分别是以武田信玄等人为主的《关东三国志》，织田信长等人为主的《战国三杰》，石田三成等人为主的《关原的年轻武者》，丰富游戏内的剧情。此部份专门介绍角色，欲知武器情报、奥义字或擅长攻击类型等，请至战国无双系列1.由于乡里大辅先生因故去世，不得不寻找其他声优接手。从猛将传 and Z开始。2.战国无双 编年史的原创男女主角亦有专属声优。此模式是任天堂游戏谜之村雨城改编的新增模式。本作中共有20张战场地图（不含村雨城），后来发行的猛将传再新增3张战场地图。但游戏内战役数量繁多，部分地图会有兼用的状况，战役虚实则是以光荣发行的2本「战国无双3 人物真书」内容为主，以下是相关介绍。（注：前方加☆者为猛将传新增关卡及地图。）合并本篇和猛将传的内容，村雨城模式剔除，战国史模式可直接游玩。主打两大模式「战史演武」&「争霸演武」。系列作品外传作品\n",
      "《战国无双3》是由哪两个公司合作开发的？\n",
      "['《', '战', '国', '无', '双', '3', '》', '（', '）', '是', '由', '光', '荣', '和', 'ω', '-', 'f', 'o', 'r', 'c', 'e', '开', '发', '的', '战', '国', '无', '双', '系', '列', '的', '正', '统', '第', '三', '续', '作', '。', '本', '作', '以', '三', '大', '故', '事', '为', '主', '轴', '，', '分', '别', '是', '以', '武', '田', '信', '玄', '等', '人', '为', '主', '的', '《', '关', '东', '三', '国', '志', '》', '，', '织', '田', '信', '长', '等', '人', '为', '主', '的', '《', '战', '国', '三', '杰', '》', '，', '石', '田', '三', '成', '等', '人', '为', '主', '的', '《', '关', '原', '的', '年', '轻', '武', '者', '》', '，', '丰', '富', '游', '戏', '内', '的', '剧', '情', '。', '此', '部', '份', '专', '门', '介', '绍', '角', '色', '，', '欲', '知', '武', '器', '情', '报', '、', '奥', '义', '字', '或', '擅', '长', '攻', '击', '类', '型', '等', '，', '请', '至', '战', '国', '无', '双', '系', '列', '1', '.', '由', '于', '乡', '里', '大', '辅', '先', '生', '因', '故', '去', '世', '，', '不', '得', '不', '寻', '找', '其', '他', '声', '优', '接', '手', '。', '从', '猛', '将', '传', ' ', 'a', 'n', 'd', ' ', 'Z', '开', '始', '。', '2', '.', '战', '国', '无', '双', ' ', '编', '年', '史', '的', '原', '创', '男', '女', '主', '角', '亦', '有', '专', '属', '声', '优', '。', '此', '模', '式', '是', '任', '天', '堂', '游', '戏', '谜', '之', '村', '雨', '城', '改', '编', '的', '新', '增', '模', '式', '。', '本', '作', '中', '共', '有', '2', '0', '张', '战', '场', '地', '图', '（', '不', '含', '村', '雨', '城', '）', '，', '后', '来', '发', '行', '的', '猛', '将', '传', '再', '新', '增', '3', '张', '战', '场', '地', '图', '。', '但', '游', '戏', '内', '战', '役', '数', '量', '繁', '多', '，', '部', '分', '地', '图', '会', '有', '兼', '用', '的', '状', '况', '，', '战', '役', '虚', '实', '则', '是', '以', '光', '荣', '发', '行', '的', '2', '本', '「', '战', '国', '无', '双', '3', ' ', '人', '物', '真', '书', '」', '内', '容', '为', '主', '，', '以', '下', '是', '相', '关', '介', '绍', '。', '（', '注', '：', '前', '方', '加', '☆', '者', '为', '猛', '将', '传', '新', '增', '关', '卡', '及', '地', '图', '。', '）', '合', '并', '本', '篇', '和', '猛', '将', '传', '的', '内', '容', '，', '村', '雨', '城', '模', '式', '剔', '除', '，', '战', '国', '史', '模', '式', '可', '直', '接', '游', '玩', '。', '主', '打', '两', '大', '模', '式', '「', '战', '史', '演', '武', '」', '&', '「', '争', '霸', '演', '武', '」', '。', '系', '列', '作', '品', '外', '传', '作', '品']\n",
      "['《', '战', '国', '无', '双', '3', '》', '是', '由', '哪', '两', '个', '公', '司', '合', '作', '开', '发', '的', '？']\n",
      "========================================\n",
      "417\n",
      "20\n",
      "440\n",
      "<<<<<<<<<<<<<<<<<<<<\n",
      "11\n",
      "['光荣和ω-force', '光荣和ω-force', '光荣和ω-force']\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "new_ds = DataSet()\n",
    "i=0\n",
    "for ins in ds:\n",
    "#     i=i+1\n",
    "    new_ins = deepcopy(ins)\n",
    "    context = ins['context']\n",
    "    question = ins['question']\n",
    "    print(context)\n",
    "    print(question)\n",
    "    cnt_lst = tokenizer(context)\n",
    "    print(cnt_lst)\n",
    "    q_lst = tokenizer(question)\n",
    "    print(q_lst)\n",
    "    answer_start = -1\n",
    "    print('=='*20)\n",
    "    print(len(cnt_lst))\n",
    "    print(len(q_lst))\n",
    "    print(len(cnt_lst) + len(q_lst) + 3)\n",
    "    if len(cnt_lst) + len(q_lst) + 3 > max_len:  \n",
    "        # 预留开头的[CLS]和[SEP]和中间的[sep]\n",
    "        if 'answer_starts' in ins and 'answers' in ins:\n",
    "            answer_start = int(ins['answer_starts'][0])\n",
    "            print('answer_start',answer_start)\n",
    "            answer = ins['answers'][0]\n",
    "            answer_end = answer_start + len(answer)\n",
    "            if answer_end > max_len - 3 - len(q_lst):\n",
    "                span_start = answer_end + 3 + len(q_lst) - max_len\n",
    "                span_end = answer_end\n",
    "            else:\n",
    "                span_start = 0\n",
    "                span_end = max_len - 3 - len(q_lst)\n",
    "            cnt_lst = cnt_lst[span_start:span_end]\n",
    "            answer_start = int(ins['answer_starts'][0])\n",
    "            answer_start -= span_start\n",
    "            answer_end = answer_start + len(ins['answers'][0])\n",
    "        else:\n",
    "            cnt_lst = cnt_lst[:max_len - len(q_lst) - 3]\n",
    "    else:\n",
    "        if 'answer_starts' in ins and 'answers' in ins:\n",
    "            answer_start = int(ins['answer_starts'][0])\n",
    "            print('<'*20)\n",
    "            print(answer_start)\n",
    "            answer_end = answer_start + len(ins['answers'][0])\n",
    "            print(ins['answers'])\n",
    "            print(answer_end)\n",
    "    tokens = cnt_lst + ['[SEP]'] + q_lst\n",
    "    new_ins['context_len'] = len(cnt_lst)\n",
    "    new_ins['raw_chars'] = tokens\n",
    "    if answer_start != -1:\n",
    "            new_ins['target_start'] = answer_start\n",
    "#             print(answer_start)\n",
    "            new_ins['target_end'] = answer_end - 1\n",
    "#             print(answer_end-1)\n",
    "\n",
    "    new_ds.append(new_ins)\n",
    "    data_bundle=DataBundle()\n",
    "    name='dev'\n",
    "    data_bundle.set_dataset(new_ds, name)\n",
    "        \n",
    "    if i==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# answer_starts \n",
    "原来指的是答案在什么位置上面\n",
    "# answer_end\n",
    "原来值得是答案的最后位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-------------+-------------+---------------+-------------+---------------+------------+-------------+---------------+--------------+------------+\n",
       "| title       | context     | question      | answers     | answer_starts | id         | context_len | raw_chars     | target_start | target_end |\n",
       "+-------------+-------------+---------------+-------------+---------------+------------+-------------+---------------+--------------+------------+\n",
       "| 战国无双... | 《战国无... | 《战国无双... | ['光荣和... | [11, 11, 11]  | DEV_0_Q... | 417         | ['《', '战... | 11           | 20         |\n",
       "+-------------+-------------+---------------+-------------+---------------+------------+-------------+---------------+--------------+------------+"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastNLP import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocabulary(['《', '战', '国', '无', '双']...)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab.from_dataset(*[ds for name, ds in data_bundle.iter_datasets() \n",
    "                                 if 'train' in name],\n",
    "                               field_name='raw_chars',\n",
    "                               no_create_entry_dataset=[ds for name, ds in data_bundle.iter_datasets()\n",
    "                                                        if 'train' not in name]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vocabulary(['《', '战', '国', '无', '双']...)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab.index_dataset(*data_bundle.datasets.values()\n",
    "                                , field_name='raw_chars', new_field_name='chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In total 1 datasets:\n",
       "\tdev has 1 instances.\n",
       "In total 1 vocabs:\n",
       "\tchars has 213 entries."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.set_vocab(src_vocab, 'chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In total 1 datasets:\n",
       "\tdev has 1 instances.\n",
       "In total 1 vocabs:\n",
       "\tchars has 213 entries."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.set_ignore_type('raw_chars', 'answers', flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_bundle.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In total 1 datasets:\n",
       "\tdev has 1 instances.\n",
       "In total 1 vocabs:\n",
       "\tchars has 213 entries."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.set_input('chars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
       "| title     | context     | question      | answers     | answer_starts | id        | context_len | raw_chars     | target_start | target_end | chars     |\n",
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
       "| 战国无... | 《战国无... | 《战国无双... | ['光荣和... | [11, 11, 11]  | DEV_0_... | 417         | ['《', '战... | 11           | 20         | [13, 3... |\n",
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In total 1 datasets:\n",
       "\tdev has 1 instances.\n",
       "In total 1 vocabs:\n",
       "\tchars has 213 entries."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.set_target('raw_chars', \n",
    "                               'answers',\n",
    "                               'target_start',\n",
    "                               'target_end',\n",
    "                               'context_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In total 1 datasets:\n",
       "\tdev has 1 instances.\n",
       "In total 1 vocabs:\n",
       "\twords has 213 entries."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.rename_field('chars', 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
       "| title     | context     | question      | answers     | answer_starts | id        | context_len | raw_chars     | target_start | target_end | chars     |\n",
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
       "| 战国无... | 《战国无... | 《战国无双... | ['光荣和... | [11, 11, 11]  | DEV_0_... | 417         | ['《', '战... | 11           | 20         | [13, 3... |\n",
       "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.get_dataset('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dev'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle.datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = data_bundle.get_dataset('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
      "| title     | context     | question      | answers     | answer_starts | id        | context_len | raw_chars     | target_start | target_end | words     |\n",
      "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n",
      "| 战国无... | 《战国无... | 《战国无双... | ['光荣和... | [11, 11, 11]  | DEV_0_... | 417         | ['《', '战... | 11           | 20         | [13, 3... |\n",
      "+-----------+-------------+---------------+-------------+---------------+-----------+-------------+---------------+--------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for ins in ds:\n",
    "    print(ins)\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'战国无双3'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'《战国无双3》（）是由光荣和ω-force开发的战国无双系列的正统第三续作。本作以三大故事为主轴，分别是以武田信玄等人为主的《关东三国志》，织田信长等人为主的《战国三杰》，石田三成等人为主的《关原的年轻武者》，丰富游戏内的剧情。此部份专门介绍角色，欲知武器情报、奥义字或擅长攻击类型等，请至战国无双系列1.由于乡里大辅先生因故去世，不得不寻找其他声优接手。从猛将传 and Z开始。2.战国无双 编年史的原创男女主角亦有专属声优。此模式是任天堂游戏谜之村雨城改编的新增模式。本作中共有20张战场地图（不含村雨城），后来发行的猛将传再新增3张战场地图。但游戏内战役数量繁多，部分地图会有兼用的状况，战役虚实则是以光荣发行的2本「战国无双3 人物真书」内容为主，以下是相关介绍。（注：前方加☆者为猛将传新增关卡及地图。）合并本篇和猛将传的内容，村雨城模式剔除，战国史模式可直接游玩。主打两大模式「战史演武」&「争霸演武」。系列作品外传作品'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['context'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'《战国无双3》是由哪两个公司合作开发的？'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['光荣和ω-force', '光荣和ω-force', '光荣和ω-force']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['answers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 11, 11]\n",
      "417\n",
      "['《', '战', '国', '无', '双', '3', '》', '（', '）', '是', '由', '光', '荣', '和', 'ω', '-', 'f', 'o', 'r', 'c', 'e', '开', '发', '的', '战', '国', '无', '双', '系', '列', '的', '正', '统', '第', '三', '续', '作', '。', '本', '作', '以', '三', '大', '故', '事', '为', '主', '轴', '，', '分', '别', '是', '以', '武', '田', '信', '玄', '等', '人', '为', '主', '的', '《', '关', '东', '三', '国', '志', '》', '，', '织', '田', '信', '长', '等', '人', '为', '主', '的', '《', '战', '国', '三', '杰', '》', '，', '石', '田', '三', '成', '等', '人', '为', '主', '的', '《', '关', '原', '的', '年', '轻', '武', '者', '》', '，', '丰', '富', '游', '戏', '内', '的', '剧', '情', '。', '此', '部', '份', '专', '门', '介', '绍', '角', '色', '，', '欲', '知', '武', '器', '情', '报', '、', '奥', '义', '字', '或', '擅', '长', '攻', '击', '类', '型', '等', '，', '请', '至', '战', '国', '无', '双', '系', '列', '1', '.', '由', '于', '乡', '里', '大', '辅', '先', '生', '因', '故', '去', '世', '，', '不', '得', '不', '寻', '找', '其', '他', '声', '优', '接', '手', '。', '从', '猛', '将', '传', ' ', 'a', 'n', 'd', ' ', 'Z', '开', '始', '。', '2', '.', '战', '国', '无', '双', ' ', '编', '年', '史', '的', '原', '创', '男', '女', '主', '角', '亦', '有', '专', '属', '声', '优', '。', '此', '模', '式', '是', '任', '天', '堂', '游', '戏', '谜', '之', '村', '雨', '城', '改', '编', '的', '新', '增', '模', '式', '。', '本', '作', '中', '共', '有', '2', '0', '张', '战', '场', '地', '图', '（', '不', '含', '村', '雨', '城', '）', '，', '后', '来', '发', '行', '的', '猛', '将', '传', '再', '新', '增', '3', '张', '战', '场', '地', '图', '。', '但', '游', '戏', '内', '战', '役', '数', '量', '繁', '多', '，', '部', '分', '地', '图', '会', '有', '兼', '用', '的', '状', '况', '，', '战', '役', '虚', '实', '则', '是', '以', '光', '荣', '发', '行', '的', '2', '本', '「', '战', '国', '无', '双', '3', ' ', '人', '物', '真', '书', '」', '内', '容', '为', '主', '，', '以', '下', '是', '相', '关', '介', '绍', '。', '（', '注', '：', '前', '方', '加', '☆', '者', '为', '猛', '将', '传', '新', '增', '关', '卡', '及', '地', '图', '。', '）', '合', '并', '本', '篇', '和', '猛', '将', '传', '的', '内', '容', '，', '村', '雨', '城', '模', '式', '剔', '除', '，', '战', '国', '史', '模', '式', '可', '直', '接', '游', '玩', '。', '主', '打', '两', '大', '模', '式', '「', '战', '史', '演', '武', '」', '&', '「', '争', '霸', '演', '武', '」', '。', '系', '列', '作', '品', '外', '传', '作', '品', '[SEP]', '《', '战', '国', '无', '双', '3', '》', '是', '由', '哪', '两', '个', '公', '司', '合', '作', '开', '发', '的', '？']\n",
      "11\n",
      "20\n",
      "[13, 3, 6, 8, 9, 20, 14, 34, 35, 10, 36, 54, 55, 56, 85, 86, 87, 88, 89, 90, 91, 37, 21, 2, 3, 6, 8, 9, 38, 39, 2, 92, 93, 94, 15, 95, 11, 5, 22, 11, 23, 15, 40, 57, 96, 12, 7, 97, 4, 58, 98, 10, 23, 16, 41, 59, 99, 24, 25, 12, 7, 2, 13, 26, 100, 15, 6, 101, 14, 4, 102, 41, 59, 60, 24, 25, 12, 7, 2, 13, 3, 6, 15, 103, 14, 4, 104, 41, 15, 105, 24, 25, 12, 7, 2, 13, 26, 61, 2, 62, 106, 16, 63, 14, 4, 107, 108, 27, 42, 28, 2, 109, 64, 5, 65, 66, 110, 67, 111, 68, 69, 70, 112, 4, 113, 114, 16, 115, 64, 116, 117, 118, 119, 120, 121, 122, 60, 123, 124, 125, 126, 24, 4, 127, 128, 3, 6, 8, 9, 38, 39, 129, 71, 36, 130, 131, 132, 40, 133, 134, 135, 136, 57, 137, 138, 4, 43, 139, 43, 140, 141, 142, 143, 72, 73, 74, 144, 5, 145, 29, 30, 17, 31, 146, 147, 148, 31, 149, 37, 150, 5, 44, 71, 3, 6, 8, 9, 31, 75, 62, 45, 2, 61, 151, 152, 153, 7, 70, 154, 46, 67, 155, 72, 73, 5, 65, 18, 19, 10, 156, 157, 158, 27, 42, 159, 160, 47, 48, 49, 161, 75, 2, 50, 51, 18, 19, 5, 22, 11, 162, 163, 46, 44, 164, 76, 3, 77, 32, 33, 34, 43, 165, 47, 48, 49, 35, 4, 166, 167, 21, 78, 2, 29, 30, 17, 168, 50, 51, 20, 76, 3, 77, 32, 33, 5, 169, 27, 42, 28, 3, 79, 170, 171, 172, 173, 4, 66, 58, 32, 33, 174, 46, 175, 176, 2, 177, 178, 4, 3, 79, 179, 180, 181, 10, 23, 54, 55, 21, 78, 2, 44, 22, 52, 3, 6, 8, 9, 20, 31, 25, 182, 183, 184, 53, 28, 80, 12, 7, 4, 23, 185, 10, 186, 26, 68, 69, 5, 34, 187, 188, 189, 190, 191, 192, 63, 12, 29, 30, 17, 50, 51, 26, 193, 194, 32, 33, 5, 35, 81, 195, 22, 196, 56, 29, 30, 17, 2, 28, 80, 4, 47, 48, 49, 18, 19, 197, 198, 4, 3, 6, 45, 18, 19, 199, 200, 74, 27, 201, 5, 7, 202, 82, 40, 18, 19, 52, 3, 45, 83, 16, 53, 203, 52, 204, 205, 83, 16, 53, 5, 38, 39, 11, 84, 206, 17, 11, 84, 207, 13, 3, 6, 8, 9, 20, 14, 10, 36, 208, 82, 209, 210, 211, 81, 11, 37, 21, 2, 212]\n"
     ]
    }
   ],
   "source": [
    "print(ds['answer_starts'][0])\n",
    "print(ds['context_len'][0])\n",
    "print(ds['raw_chars'][0])\n",
    "print(ds['target_start'][0])\n",
    "print(ds['target_end'][0])\n",
    "print(ds['words'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In total 1 datasets:\n",
       "\tdev has 1 instances."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+---------------+-------------+---------------+------------+-------------+---------------+--------------+------------+\n",
      "| title       | context     | question      | answers     | answer_starts | id         | context_len | raw_chars     | target_start | target_end |\n",
      "+-------------+-------------+---------------+-------------+---------------+------------+-------------+---------------+--------------+------------+\n",
      "| 战国无双... | 《战国无... | 《战国无双... | ['光荣和... | [11, 11, 11]  | DEV_0_Q... | 417         | ['《', '战... | 11           | 20         |\n",
      "+-------------+-------------+---------------+-------------+---------------+------------+-------------+---------------+--------------+------------+\n"
     ]
    }
   ],
   "source": [
    "print(new_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+-----------------+-----------------+-------------------+----------------+\n",
      "| title          | context         | question        | answers         | answer_starts     | id             |\n",
      "+----------------+-----------------+-----------------+-----------------+-------------------+----------------+\n",
      "| 战国无双3      | 《战国无双3...  | 《战国无双3...  | ['光荣和ω-...   | [11, 11, 11]      | DEV_0_QUERY... |\n",
      "| 战国无双3      | 《战国无双3...  | 男女主角亦有... | ['村雨城', ...  | [226, 226, 219... | DEV_0_QUERY... |\n",
      "| 战国无双3      | 《战国无双3...  | 战国史模式主... | ['「战史演武... | [395, 395, 395... | DEV_0_QUERY... |\n",
      "| 锣鼓经         | 锣鼓经是大陆... | 锣鼓经是什么... | ['大陆传统器... | [4, 4, 4]         | DEV_1_QUERY... |\n",
      "| 锣鼓经         | 锣鼓经是大陆... | 锣鼓经常用的... | ['锣鼓点', ...  | [67, 67, 67]      | DEV_1_QUERY... |\n",
      "| 锣鼓经         | 锣鼓经是大陆... | 锣鼓经运用的... | ['依照角色行... | [167, 167, 167... | DEV_1_QUERY... |\n",
      "| 锣鼓经         | 锣鼓经是大陆... | 戏曲锣鼓所运... | ['鼓、锣、钹... | [237, 237, 237... | DEV_1_QUERY... |\n",
      "| 广茂铁路       | 广茂铁路是中... | 广茂铁路全长... | ['364.6公里...  | [60, 60, 60]      | DEV_2_QUERY... |\n",
      "| 广茂铁路       | 广茂铁路是中... | 广茂铁路由哪... | ['三茂铁路股... | [69, 69, 69]      | DEV_2_QUERY... |\n",
      "| 广茂铁路       | 广茂铁路是中... | 广三铁路在哪... | ['1903年', ...  | [398, 398, 398... | DEV_2_QUERY... |\n",
      "| 大莱龙铁路     | 大莱龙铁路位... | 大莱龙铁路位... | ['山东省北部... | [7, 7, 7]         | DEV_3_QUERY... |\n",
      "| 大莱龙铁路     | 大莱龙铁路位... | 大莱龙铁路一... | ['11.42亿元...  | [104, 104, 104... | DEV_3_QUERY... |\n",
      "| 大莱龙铁路     | 大莱龙铁路位... | 大莱龙铁路有... | ['是横贯山东... | [190, 190, 191... | DEV_3_QUERY... |\n",
      "| 大莱龙铁路     | 大莱龙铁路位... | 铁路沿线设有... | ['大家洼站、... | [249, 249, 249... | DEV_3_QUERY... |\n",
      "| 莱昂德罗·内... | 莱昂德罗·内...  | 莱昂德罗·内...  | ['巴西', '巴... | [34, 34, 34]      | DEV_4_QUERY... |\n",
      "| 莱昂德罗·内... | 莱昂德罗·内...  | 莱昂德罗·内...  | ['足球运动员... | [36, 36, 36]      | DEV_4_QUERY... |\n",
      "| 莱昂德罗·内... | 莱昂德罗·内...  | 莱昂德罗·内...  | ['葡萄牙、塞... | [60, 60, 60]      | DEV_4_QUERY... |\n",
      "| 赵鹏           | 赵鹏（），中... | 赵鹏的职业是... | ['足球运动员... | [7, 7, 7]         | DEV_5_QUERY... |\n",
      "| 赵鹏           | 赵鹏（），中... | 赵鹏在2014年... | ['伤病困扰'...  | [287, 287, 287... | DEV_5_QUERY... |\n",
      "| 赵鹏           | 赵鹏（），中... | 赵鹏在哪年入... | ['2009年', ...  | [335, 335, 335... | DEV_5_QUERY... |\n",
      "| 邹游           | 邹游（），中... | 邹游的职业是... | ['足球运动员... | [7, 7, 7]         | DEV_6_QUERY... |\n",
      "| 邹游           | 邹游（），中... | 他司职什么位... | ['中场', '中... | [15, 15, 15]      | DEV_6_QUERY... |\n",
      "| 邹游           | 邹游（），中... | 邹游为什么被... | ['2010年是邹... | [165, -1, 130]... | DEV_6_QUERY... |\n",
      "| 邹游           | 邹游（），中... | 邹游效力抚顺... | ['10号', '1...  | [246, 246, 246... | DEV_6_QUERY... |\n",
      "| 张世昌         | 张世昌（），... | 张世昌的职业... | ['足球运动员... | [8, 8, 8]         | DEV_7_QUERY... |\n",
      "| 张世昌         | 张世昌（），... | 张世昌出名的... | ['出众的身体... | [22, 22, 22]      | DEV_7_QUERY... |\n",
      "| 张世昌         | 张世昌（），... | 张世昌为什么... | ['因曾诚的不... | [317, 317, 317... | DEV_7_QUERY... |\n",
      "| 于乐           | 于乐（），中... | 于乐的职业是... | ['足球运动员... | [7, 7, 7]         | DEV_8_QUERY... |\n",
      "| 于乐           | 于乐（），中... | 于乐在哪里出... | ['北京国安'...  | [23, 23, 23]      | DEV_8_QUERY... |\n",
      "| 于乐           | 于乐（），中... | 于乐在哪一场... | ['2007年赛季... | [46, -1, 46]      | DEV_8_QUERY... |\n",
      "| 于乐           | 于乐（），中... | 2013年于乐状... | ['摆脱伤病困... | [365, 365, 363... | DEV_8_QUERY... |\n",
      "| ...            | ...             | ...             | ...             | ...               | ...            |\n",
      "+----------------+-----------------+-----------------+-----------------+-------------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_bundle.rename_field('chars', 'words')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
